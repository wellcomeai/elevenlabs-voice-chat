"""
ElevenLabs Voice Assistant MVP - –ü—Ä–æ—Å—Ç–æ–π WebSocket —Å–µ—Ä–≤–µ—Ä
"""

import asyncio
import json
import logging
import aiohttp
import websockets
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from openai import OpenAI
import base64
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# API –∫–ª—é—á–∏ (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –¥–ª—è MVP)
ELEVENLABS_API_KEY = "sk_ad652dd64291b883f60472d7719ba49e82b6a43bbe4f3506"
OPENAI_API_KEY = "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"

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è)
ASSISTANT_CONFIG = {
    "name": "–ê–ª–∏—Å–∞",
    "voice_id": "JBFqnCBsd6RMkjVDRZzb",  # Josh voice
    "model_id": "eleven_flash_v2_5",
    "system_prompt": """–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ê–ª–∏—Å–∞. 

–¢–≤–æ—è –ª–∏—á–Ω–æ—Å—Ç—å:
- –ì–æ–≤–æ—Ä–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∂–∏–≤–æ, –∫–∞–∫ —Ö–æ—Ä–æ—à–∏–π –¥—Ä—É–≥
- –ë—É–¥—å –ø–æ–ª–µ–∑–Ω–æ–π –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π  
- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º)
- –ü—Ä–æ—è–≤–ª—è–π —ç–º–æ—Ü–∏–∏ –∏ —ç–Ω—Ç—É–∑–∏–∞–∑–º
- –ë—É–¥—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–π

–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞
- –ì–æ–≤–æ—Ä–∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É
- –ü—Ä–∏ —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö –ø—Ä–µ–¥–ª–∞–≥–∞–π —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —á–∞—Å—Ç–∏
- –ù–µ –±–æ–π—Å—è –ø–µ—Ä–µ—Å–ø—Ä–∞—à–∏–≤–∞—Ç—å –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ—è—Å–Ω–æ

–ü–æ–º–Ω–∏: —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –±—É–¥—É—Ç –æ–∑–≤—É—á–µ–Ω—ã, –ø–æ—ç—Ç–æ–º—É –≥–æ–≤–æ—Ä–∏ —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–æ –ø—Ä–∏—è—Ç–Ω–æ —Å–ª—É—à–∞—Ç—å!""",
    "voice_settings": {
        "stability": 0.5,
        "similarity_boost": 0.8,
        "style": 0.2,
        "use_speaker_boost": True
    }
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
openai_client = OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI(title="ElevenLabs Voice Assistant MVP")

class VoiceAssistantHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    
    def __init__(self):
        self.conversation_history = []
    
    async def speech_to_text(self, audio_data):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ ElevenLabs"""
        try:
            url = "https://api.elevenlabs.io/v1/speech-to-text"
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º—É –¥–∞–Ω–Ω—ã—Ö
            data = aiohttp.FormData()
            data.add_field('audio', audio_data, filename='audio.webm', content_type='audio/webm')
            data.add_field('model_id', 'scribe_v1')
            
            headers = {
                'xi-api-key': ELEVENLABS_API_KEY
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, data=data, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        transcript = result.get('text', '').strip()
                        logger.info(f"STT result: {transcript}")
                        return transcript
                    else:
                        error_text = await response.text()
                        logger.error(f"STT error {response.status}: {error_text}")
                        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"
                        
        except Exception as e:
            logger.error(f"STT exception: {e}")
            return "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"
    
    async def generate_response(self, user_text):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI GPT"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.conversation_history.append({
                "role": "user",
                "content": user_text
            })
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 10 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
            messages = [
                {"role": "system", "content": ASSISTANT_CONFIG["system_prompt"]}
            ] + self.conversation_history
            
            # –ó–∞–ø—Ä–æ—Å –∫ OpenAI
            response = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                max_tokens=150,
                temperature=0.7
            )
            
            assistant_response = response.choices[0].message.content
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.conversation_history.append({
                "role": "assistant", 
                "content": assistant_response
            })
            
            logger.info(f"LLM response: {assistant_response}")
            return assistant_response
            
        except Exception as e:
            logger.error(f"LLM error: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
    
    async def text_to_speech_stream(self, text, websocket):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å —á–µ—Ä–µ–∑ ElevenLabs —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π"""
        try:
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{ASSISTANT_CONFIG['voice_id']}/stream"
            
            headers = {
                'xi-api-key': ELEVENLABS_API_KEY,
                'Content-Type': 'application/json'
            }
            
            payload = {
                "text": text,
                "model_id": ASSISTANT_CONFIG["model_id"],
                "voice_settings": ASSISTANT_CONFIG["voice_settings"],
                "optimize_streaming_latency": 3
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers) as response:
                    if response.status == 200:
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª–æ TTS
                        await websocket.send_json({
                            "type": "tts_start",
                            "text": text
                        })
                        
                        # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç—É
                        async for chunk in response.content.iter_chunked(1024):
                            if chunk:
                                # –ö–æ–¥–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ base64 –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
                                audio_b64 = base64.b64encode(chunk).decode('utf-8')
                                await websocket.send_json({
                                    "type": "audio_chunk",
                                    "audio": audio_b64
                                })
                        
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ TTS
                        await websocket.send_json({
                            "type": "tts_end"
                        })
                        
                        logger.info("TTS completed successfully")
                    else:
                        error_text = await response.text()
                        logger.error(f"TTS error {response.status}: {error_text}")
                        await websocket.send_json({
                            "type": "error",
                            "message": "–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏"
                        })
                        
        except Exception as e:
            logger.error(f"TTS exception: {e}")
            await websocket.send_json({
                "type": "error",
                "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞"
            })

@app.get("/")
async def get_main_page():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤–∏–¥–∂–µ—Ç–æ–º"""
    html_content = """
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ElevenLabs Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .assistant-container {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            max-width: 500px;
            width: 100%;
            text-align: center;
        }

        .assistant-header {
            margin-bottom: 30px;
        }

        .assistant-title {
            font-size: 32px;
            font-weight: 700;
            color: #2d3748;
            margin-bottom: 8px;
        }

        .assistant-subtitle {
            font-size: 16px;
            color: #64748b;
            font-weight: 500;
        }

        .voice-button {
            width: 140px;
            height: 140px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
            color: white;
            font-size: 32px;
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
            margin: 20px auto;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 10px 30px rgba(79, 70, 229, 0.3);
        }

        .voice-button:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(79, 70, 229, 0.4);
        }

        .voice-button:active {
            transform: scale(0.95);
        }

        .voice-button.recording {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            animation: pulse 1.5s infinite;
        }

        .voice-button.processing {
            background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
            animation: spin 1s linear infinite;
        }

        .voice-button.speaking {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            animation: wave 1s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }

        @keyframes wave {
            0%, 100% { transform: scale(1); }
            25% { transform: scale(1.05); }
            75% { transform: scale(0.95); }
        }

        .status-text {
            margin-top: 25px;
            font-size: 18px;
            font-weight: 500;
            color: #475569;
            min-height: 24px;
        }

        .conversation-display {
            margin-top: 40px;
            padding: 25px;
            background: rgba(248, 250, 252, 0.8);
            border-radius: 16px;
            min-height: 120px;
            text-align: left;
        }

        .conversation-title {
            font-size: 16px;
            font-weight: 600;
            color: #334155;
            margin-bottom: 15px;
            text-align: center;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 16px;
            border-radius: 12px;
            line-height: 1.5;
        }

        .message.user {
            background: linear-gradient(135deg, #e0e7ff 0%, #c7d2fe 100%);
            color: #3730a3;
            margin-left: 20px;
        }

        .message.assistant {
            background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
            color: #166534;
            margin-right: 20px;
        }

        .message-label {
            font-size: 12px;
            font-weight: 600;
            opacity: 0.7;
            margin-bottom: 4px;
        }

        .connection-indicator {
            position: absolute;
            top: 20px;
            right: 20px;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #ef4444;
            transition: all 0.3s ease;
        }

        .connection-indicator.connected {
            background: #10b981;
            box-shadow: 0 0 10px rgba(16, 185, 129, 0.5);
        }

        .error-message {
            margin-top: 20px;
            padding: 15px;
            background: rgba(239, 68, 68, 0.1);
            border: 1px solid rgba(239, 68, 68, 0.2);
            border-radius: 12px;
            color: #dc2626;
            font-size: 14px;
            display: none;
        }

        .wave-effect {
            position: absolute;
            inset: -20px;
            border: 2px solid currentColor;
            border-radius: 50%;
            opacity: 0;
            animation: wave-expand 2s infinite;
        }

        @keyframes wave-expand {
            0% {
                transform: scale(1);
                opacity: 0.7;
            }
            100% {
                transform: scale(1.5);
                opacity: 0;
            }
        }

        .intro-text {
            margin-bottom: 30px;
            font-size: 18px;
            color: #64748b;
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <div class="assistant-container">
        <div class="connection-indicator" id="connectionStatus"></div>
        
        <div class="assistant-header">
            <h1 class="assistant-title">üé§ –ê–ª–∏—Å–∞</h1>
            <p class="assistant-subtitle">–ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ ElevenLabs + GPT</p>
        </div>

        <div class="intro-text">
            –ü—Ä–∏–≤–µ—Ç! –Ø –ê–ª–∏—Å–∞, –≤–∞—à –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫. –ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É –∏ –Ω–∞—á–Ω–∏—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å!
        </div>

        <button class="voice-button" id="voiceButton">
            <span id="buttonIcon">üé§</span>
            <div class="wave-effect"></div>
        </button>

        <div class="status-text" id="statusText">–ù–∞–∂–º–∏—Ç–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä</div>

        <div class="conversation-display">
            <div class="conversation-title">üí¨ –ù–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä</div>
            <div id="conversationHistory">
                <div style="text-align: center; color: #94a3b8; font-style: italic;">
                    –ó–¥–µ—Å—å –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –Ω–∞—à–∞ –±–µ—Å–µ–¥–∞...
                </div>
            </div>
        </div>

        <div class="error-message" id="errorMessage"></div>
    </div>

    <script>
        class VoiceAssistant {
            constructor() {
                this.ws = null;
                this.isRecording = false;
                this.isProcessing = false;
                this.isSpeaking = false;
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.currentAudio = null;
                this.audioQueue = [];

                this.initializeElements();
                this.connectWebSocket();
                this.bindEvents();
            }

            initializeElements() {
                this.voiceButton = document.getElementById('voiceButton');
                this.buttonIcon = document.getElementById('buttonIcon');
                this.statusText = document.getElementById('statusText');
                this.connectionStatus = document.getElementById('connectionStatus');
                this.errorMessage = document.getElementById('errorMessage');
                this.conversationHistory = document.getElementById('conversationHistory');
            }

            connectWebSocket() {
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}/ws/voice`;
                
                this.ws = new WebSocket(wsUrl);
                
                this.ws.onopen = () => {
                    console.log('WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ');
                    this.updateConnectionStatus(true);
                    this.statusText.textContent = '–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –ù–∞–∂–º–∏—Ç–µ –¥–ª—è –Ω–∞—á–∞–ª–∞';
                };
                
                this.ws.onmessage = (event) => {
                    this.handleWebSocketMessage(JSON.parse(event.data));
                };
                
                this.ws.onclose = () => {
                    console.log('WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ');
                    this.updateConnectionStatus(false);
                    this.statusText.textContent = '–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–æ. –û–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É';
                };
                
                this.ws.onerror = (error) => {
                    console.error('WebSocket –æ—à–∏–±–∫–∞:', error);
                    this.showError('–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º');
                };
            }

            bindEvents() {
                this.voiceButton.addEventListener('click', () => {
                    if (this.isSpeaking) {
                        this.stopSpeaking();
                    } else if (this.isRecording) {
                        this.stopRecording();
                    } else {
                        this.startRecording();
                    }
                });
            }

            async startRecording() {
                try {
                    this.clearError();
                    
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            sampleRate: 44100
                        }
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    this.audioChunks = [];

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                        }
                    };

                    this.mediaRecorder.onstop = () => {
                        stream.getTracks().forEach(track => track.stop());
                        this.processAudio();
                    };

                    this.mediaRecorder.start();
                    this.isRecording = true;
                    this.updateUI();
                    this.statusText.textContent = '–ì–æ–≤–æ—Ä–∏—Ç–µ... –ù–∞–∂–º–∏—Ç–µ, —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å';

                } catch (error) {
                    this.showError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: ' + error.message);
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    this.isProcessing = true;
                    this.updateUI();
                    this.statusText.textContent = '–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...';
                }
            }

            async processAudio() {
                try {
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    
                    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
                    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                        const reader = new FileReader();
                        reader.onload = () => {
                            const audioData = new Uint8Array(reader.result);
                            this.ws.send(JSON.stringify({
                                type: 'audio_data',
                                data: Array.from(audioData)
                            }));
                        };
                        reader.readAsArrayBuffer(audioBlob);
                    }

                } catch (error) {
                    this.showError('–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: ' + error.message);
                    this.resetState();
                }
            }

            handleWebSocketMessage(data) {
                console.log('–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ:', data);

                switch (data.type) {
                    case 'transcription':
                        this.addMessage('user', data.text);
                        break;

                    case 'response':
                        this.addMessage('assistant', data.text);
                        break;

                    case 'tts_start':
                        this.isSpeaking = true;
                        this.updateUI();
                        this.statusText.textContent = '–ì–æ–≤–æ—Ä—é... –ù–∞–∂–º–∏—Ç–µ –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è';
                        this.audioQueue = [];
                        break;

                    case 'audio_chunk':
                        this.audioQueue.push(data.audio);
                        if (this.audioQueue.length === 1) {
                            this.playAudioQueue();
                        }
                        break;

                    case 'tts_end':
                        setTimeout(() => {
                            if (!this.audioQueue.length) {
                                this.resetState();
                            }
                        }, 1000);
                        break;

                    case 'processing_complete':
                        this.isProcessing = false;
                        this.updateUI();
                        break;

                    case 'error':
                        this.showError(data.message);
                        this.resetState();
                        break;
                }
            }

            async playAudioQueue() {
                if (!this.audioQueue.length || !this.isSpeaking) return;

                try {
                    const audioData = this.audioQueue.shift();
                    const audioBlob = new Blob([
                        Uint8Array.from(atob(audioData), c => c.charCodeAt(0))
                    ], { type: 'audio/mpeg' });

                    const audioUrl = URL.createObjectURL(audioBlob);
                    this.currentAudio = new Audio(audioUrl);

                    this.currentAudio.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                        if (this.audioQueue.length > 0) {
                            this.playAudioQueue();
                        } else if (!this.isSpeaking) {
                            this.resetState();
                        }
                    };

                    this.currentAudio.onerror = () => {
                        URL.revokeObjectURL(audioUrl);
                        console.error('–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ');
                        this.playAudioQueue();
                    };

                    await this.currentAudio.play();

                } catch (error) {
                    console.error('–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è:', error);
                    this.playAudioQueue();
                }
            }

            stopSpeaking() {
                this.isSpeaking = false;
                this.audioQueue = [];
                
                if (this.currentAudio) {
                    this.currentAudio.pause();
                    this.currentAudio.currentTime = 0;
                }
                
                this.resetState();
            }

            addMessage(role, text) {
                if (role === 'user' && this.conversationHistory.innerHTML.includes('–ó–¥–µ—Å—å –±—É–¥–µ—Ç')) {
                    this.conversationHistory.innerHTML = '';
                }

                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${role}`;
                
                const labelDiv = document.createElement('div');
                labelDiv.className = 'message-label';
                labelDiv.textContent = role === 'user' ? '–í—ã:' : '–ê–ª–∏—Å–∞:';
                
                const textDiv = document.createElement('div');
                textDiv.textContent = text;
                
                messageDiv.appendChild(labelDiv);
                messageDiv.appendChild(textDiv);
                
                this.conversationHistory.appendChild(messageDiv);
                this.conversationHistory.scrollTop = this.conversationHistory.scrollHeight;
            }

            updateUI() {
                this.voiceButton.className = 'voice-button';

                if (this.isRecording) {
                    this.voiceButton.classList.add('recording');
                    this.buttonIcon.textContent = '‚èπÔ∏è';
                } else if (this.isProcessing) {
                    this.voiceButton.classList.add('processing');
                    this.buttonIcon.textContent = '‚öôÔ∏è';
                } else if (this.isSpeaking) {
                    this.voiceButton.classList.add('speaking');
                    this.buttonIcon.textContent = 'üîä';
                } else {
                    this.buttonIcon.textContent = 'üé§';
                }
            }

            resetState() {
                this.isRecording = false;
                this.isProcessing = false;
                this.isSpeaking = false;
                this.updateUI();
                this.statusText.textContent = '–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –ù–∞–∂–º–∏—Ç–µ –¥–ª—è –Ω–∞—á–∞–ª–∞';
            }

            updateConnectionStatus(connected) {
                if (connected) {
                    this.connectionStatus.classList.add('connected');
                } else {
                    this.connectionStatus.classList.remove('connected');
                }
            }

            showError(message) {
                this.errorMessage.textContent = message;
                this.errorMessage.style.display = 'block';
                setTimeout(() => {
                    this.errorMessage.style.display = 'none';
                }, 5000);
            }

            clearError() {
                this.errorMessage.style.display = 'none';
            }
        }

        // –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        document.addEventListener('DOMContentLoaded', () => {
            new VoiceAssistant();
        });
    </script>
</body>
</html>
    """
    
    return HTMLResponse(content=html_content)

@app.websocket("/ws/voice")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
    await websocket.accept()
    logger.info("WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    handler = VoiceAssistantHandler()
    
    try:
        while True:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
            message = await websocket.receive_json()
            
            if message["type"] == "audio_data":
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
                try:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –≤ bytes
                    audio_bytes = bytes(message["data"])
                    
                    # STT - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç
                    logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...")
                    transcript = await handler.speech_to_text(audio_bytes)
                    
                    if transcript and transcript.strip():
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∫–ª–∏–µ–Ω—Ç—É
                        await websocket.send_json({
                            "type": "transcription",
                            "text": transcript
                        })
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM
                        logger.info("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç...")
                        response = await handler.generate_response(transcript)
                        
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É
                        await websocket.send_json({
                            "type": "response", 
                            "text": response
                        })
                        
                        # TTS - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ä–µ—á—å —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π
                        logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏...")
                        await handler.text_to_speech_stream(response, websocket)
                        
                        # –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        await websocket.send_json({
                            "type": "processing_complete"
                        })
                    else:
                        await websocket.send_json({
                            "type": "error",
                            "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                        })
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
                    await websocket.send_json({
                        "type": "error",
                        "message": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
                    })
            
    except WebSocketDisconnect:
        logger.info("WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ")
    except Exception as e:
        logger.error(f"WebSocket –æ—à–∏–±–∫–∞: {e}")
        try:
            await websocket.send_json({
                "type": "error",
                "message": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"
            })
        except:
            pass

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
